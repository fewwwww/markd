{"version":3,"sources":["../node_modules/@codemirror/legacy-modes/mode/oz.js"],"names":["wordRegexp","words","RegExp","join","singleOperators","doubleOperators","tripleOperators","middle","end","atoms","commonKeywords","openingKeywords","middleKeywords","endKeywords","tokenBase","stream","state","eatSpace","match","matched","doInCurrentLine","currentIndent","tokenize","tokenFunProc","tokenClass","tokenMeth","quote","ch","next","escaped","test","peek","skipToEnd","eat","tokenComment","eatWhile","hasPassedFirstStage","maybeEnd","oz","startState","token","sol","indent","textAfter","cx","trueText","replace","unit","languageData","indentOnInut","allClosings","concat","buildElectricInputRegEx","commentTokens","line","block","open","close"],"mappings":"qGAAA,SAASA,EAAWC,GAClB,OAAO,IAAIC,OAAO,MAAQD,EAAME,KAAK,OAAS,SADhD,0CAIA,IAAIC,EAAkB,4BAClBC,EAAkB,sEAClBC,EAAkB,6BAClBC,EAAS,CAAC,KAAM,OAAQ,OAAQ,KAAM,SAAU,WAAY,SAAU,QAAS,UAAW,OAAQ,UAAW,UAAW,SAAU,SAAU,SAAU,MACtJC,EAAM,CAAC,OACPC,EAAQT,EAAW,CAAC,OAAQ,QAAS,MAAO,SAC5CU,EAAiBV,EAAW,CAAC,UAAW,KAAM,OAAQ,UAAW,OAAQ,OAAQ,MAAO,MAAO,MAAO,OAAQ,SAAU,SAAU,OAAQ,OAAQ,UAAW,OAAQ,MAAO,UAC5KW,EAAkBX,EAAW,CAAC,QAAS,OAAQ,MAAO,OAAQ,QAAS,KAAM,OAAQ,KAAM,MAAO,SAAU,MAAO,SAAU,MAAO,QAAS,OAAQ,MAAO,WAAY,OAAQ,YAChLY,EAAiBZ,EAAWO,GAC5BM,EAAcb,EAAWQ,GAE7B,SAASM,EAAUC,EAAQC,GACzB,GAAID,EAAOE,WACT,OAAO,KAIT,GAAIF,EAAOG,MAAM,QACf,MAAO,UAIT,GAAIH,EAAOG,MAAM,MACf,MAAO,UAIT,GAAIH,EAAOG,MAAMZ,IAAoBS,EAAOG,MAAMb,GAChD,MAAO,WAIT,GAAIU,EAAOG,MAAMT,GACf,MAAO,OAIT,IAAIU,EAAUJ,EAAOG,MAAMP,GAE3B,GAAIQ,EAIF,OAHKH,EAAMI,gBAA4CJ,EAAMI,iBAAkB,EAAnDJ,EAAMK,gBAEhB,QAAdF,EAAQ,IAA8B,OAAdA,EAAQ,GAAaH,EAAMM,SAAWC,EAAoC,SAAdJ,EAAQ,GAAeH,EAAMM,SAAWE,EAAkC,QAAdL,EAAQ,KAAcH,EAAMM,SAAWG,GACpL,UAIT,GAAIV,EAAOG,MAAMN,IAAmBG,EAAOG,MAAMR,GAC/C,MAAO,UAIT,GAAIK,EAAOG,MAAML,GAEf,OADAG,EAAMK,gBACC,UAIT,IA6FmBK,EA7FfC,EAAKZ,EAAOa,OAEhB,GAAU,KAAND,GAAmB,KAANA,EAEf,OADAX,EAAMM,UA0FWI,EA1FYC,EA2FxB,SAAUZ,EAAQC,GAKvB,IAJA,IACIY,EADAC,GAAU,EAEVrB,GAAM,EAEuB,OAAzBoB,EAAOb,EAAOa,SAAiB,CACrC,GAAIA,GAAQF,IAAUG,EAAS,CAC7BrB,GAAM,EACN,MAGFqB,GAAWA,GAAmB,MAARD,EAIxB,OADIpB,GAAQqB,IAASb,EAAMM,SAAWR,GAC/B,WAzGAE,EAAMM,SAASP,EAAQC,GAIhC,GAAI,QAAQc,KAAKH,GAAK,CACpB,GAAU,KAANA,EAAW,CACb,IAAK,SAASG,KAAKf,EAAOgB,QAAS,OAAO,KAAU,GAAqB,KAAjBhB,EAAOa,QAAiBb,EAAOG,MAAM,sBAAwBH,EAAOG,MAAM,wCAAyC,MAAO,SAGpL,MAAU,KAANS,GAAaZ,EAAOG,MAAM,sBAAwBH,EAAOG,MAAM,wCAAgD,SAC5G,KAIT,MAAU,KAANS,GACFZ,EAAOiB,YACA,WACQ,KAANL,GACLZ,EAAOkB,IAAI,MACbjB,EAAMM,SAAWY,EACVA,EAAanB,EAAQC,IAK5BZ,EAAgB0B,KAAKH,GAChB,YAITZ,EAAOoB,SAAS,MACT,YAGT,SAASX,EAAWT,EAAQC,GAC1B,OAAID,EAAOE,WACF,MAGTF,EAAOG,MAAM,+BACbF,EAAMM,SAAWR,EACV,QAGT,SAASW,EAAUV,EAAQC,GACzB,OAAID,EAAOE,WACF,MAGTF,EAAOG,MAAM,kCACbF,EAAMM,SAAWR,EACV,OAGT,SAASS,EAAaR,EAAQC,GAC5B,OAAID,EAAOE,WACF,MAGJD,EAAMoB,qBAAuBrB,EAAOkB,IAAI,MAC3CjB,EAAMoB,qBAAsB,EACrB,WACEpB,EAAMoB,qBACfrB,EAAOG,MAAM,kCACbF,EAAMoB,qBAAsB,EAC5BpB,EAAMM,SAAWR,EACV,QAEPE,EAAMM,SAAWR,EACV,MAIX,SAASoB,EAAanB,EAAQC,GAI5B,IAHA,IACIW,EADAU,GAAW,EAGRV,EAAKZ,EAAOa,QAAQ,CACzB,GAAU,KAAND,GAAaU,EAAU,CACzBrB,EAAMM,SAAWR,EACjB,MAGFuB,EAAiB,KAANV,EAGb,MAAO,UA8BF,IAAIW,EAAK,CACdC,WAAY,WACV,MAAO,CACLjB,SAAUR,EACVO,cAAe,EACfD,iBAAiB,EACjBgB,qBAAqB,IAGzBI,MAAO,SAAezB,EAAQC,GAE5B,OADID,EAAO0B,QAAOzB,EAAMI,gBAAkB,GACnCJ,EAAMM,SAASP,EAAQC,IAEhC0B,OAAQ,SAAgB1B,EAAO2B,EAAWC,GACxC,IAAIC,EAAWF,EAAUG,QAAQ,aAAc,IAC/C,OAAID,EAAS3B,MAAML,IAAgBgC,EAAS3B,MAAMN,IAAmBiC,EAAS3B,MAAM,SAAiB0B,EAAGG,MAAQ/B,EAAMK,cAAgB,GAClIL,EAAMK,cAAgB,EAAU,EAC7BL,EAAMK,cAAgBuB,EAAGG,MAElCC,aAAc,CACZC,aA3BJ,WAGE,IAAIC,EAAc3C,EAAO4C,OAAO3C,GAChC,OAAO,IAAIN,OAAO,aAAegD,EAAY/C,KAAK,KAAO,MAuBzCiD,GACdC,cAAe,CACbC,KAAM,IACNC,MAAO,CACLC,KAAM,KACNC,MAAO","file":"static/js/67.23b28f61.chunk.js","sourcesContent":["function wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\n\nvar singleOperators = /[\\^@!\\|<>#~\\.\\*\\-\\+\\\\/,=]/;\nvar doubleOperators = /(<-)|(:=)|(=<)|(>=)|(<=)|(<:)|(>:)|(=:)|(\\\\=)|(\\\\=:)|(!!)|(==)|(::)/;\nvar tripleOperators = /(:::)|(\\.\\.\\.)|(=<:)|(>=:)/;\nvar middle = [\"in\", \"then\", \"else\", \"of\", \"elseof\", \"elsecase\", \"elseif\", \"catch\", \"finally\", \"with\", \"require\", \"prepare\", \"import\", \"export\", \"define\", \"do\"];\nvar end = [\"end\"];\nvar atoms = wordRegexp([\"true\", \"false\", \"nil\", \"unit\"]);\nvar commonKeywords = wordRegexp([\"andthen\", \"at\", \"attr\", \"declare\", \"feat\", \"from\", \"lex\", \"mod\", \"div\", \"mode\", \"orelse\", \"parser\", \"prod\", \"prop\", \"scanner\", \"self\", \"syn\", \"token\"]);\nvar openingKeywords = wordRegexp([\"local\", \"proc\", \"fun\", \"case\", \"class\", \"if\", \"cond\", \"or\", \"dis\", \"choice\", \"not\", \"thread\", \"try\", \"raise\", \"lock\", \"for\", \"suchthat\", \"meth\", \"functor\"]);\nvar middleKeywords = wordRegexp(middle);\nvar endKeywords = wordRegexp(end); // Tokenizers\n\nfunction tokenBase(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  } // Brackets\n\n\n  if (stream.match(/[{}]/)) {\n    return \"bracket\";\n  } // Special [] keyword\n\n\n  if (stream.match('[]')) {\n    return \"keyword\";\n  } // Operators\n\n\n  if (stream.match(tripleOperators) || stream.match(doubleOperators)) {\n    return \"operator\";\n  } // Atoms\n\n\n  if (stream.match(atoms)) {\n    return 'atom';\n  } // Opening keywords\n\n\n  var matched = stream.match(openingKeywords);\n\n  if (matched) {\n    if (!state.doInCurrentLine) state.currentIndent++;else state.doInCurrentLine = false; // Special matching for signatures\n\n    if (matched[0] == \"proc\" || matched[0] == \"fun\") state.tokenize = tokenFunProc;else if (matched[0] == \"class\") state.tokenize = tokenClass;else if (matched[0] == \"meth\") state.tokenize = tokenMeth;\n    return 'keyword';\n  } // Middle and other keywords\n\n\n  if (stream.match(middleKeywords) || stream.match(commonKeywords)) {\n    return \"keyword\";\n  } // End keywords\n\n\n  if (stream.match(endKeywords)) {\n    state.currentIndent--;\n    return 'keyword';\n  } // Eat the next char for next comparisons\n\n\n  var ch = stream.next(); // Strings\n\n  if (ch == '\"' || ch == \"'\") {\n    state.tokenize = tokenString(ch);\n    return state.tokenize(stream, state);\n  } // Numbers\n\n\n  if (/[~\\d]/.test(ch)) {\n    if (ch == \"~\") {\n      if (!/^[0-9]/.test(stream.peek())) return null;else if (stream.next() == \"0\" && stream.match(/^[xX][0-9a-fA-F]+/) || stream.match(/^[0-9]*(\\.[0-9]+)?([eE][~+]?[0-9]+)?/)) return \"number\";\n    }\n\n    if (ch == \"0\" && stream.match(/^[xX][0-9a-fA-F]+/) || stream.match(/^[0-9]*(\\.[0-9]+)?([eE][~+]?[0-9]+)?/)) return \"number\";\n    return null;\n  } // Comments\n\n\n  if (ch == \"%\") {\n    stream.skipToEnd();\n    return 'comment';\n  } else if (ch == \"/\") {\n    if (stream.eat(\"*\")) {\n      state.tokenize = tokenComment;\n      return tokenComment(stream, state);\n    }\n  } // Single operators\n\n\n  if (singleOperators.test(ch)) {\n    return \"operator\";\n  } // If nothing match, we skip the entire alphanumerical block\n\n\n  stream.eatWhile(/\\w/);\n  return \"variable\";\n}\n\nfunction tokenClass(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  stream.match(/([A-Z][A-Za-z0-9_]*)|(`.+`)/);\n  state.tokenize = tokenBase;\n  return \"type\";\n}\n\nfunction tokenMeth(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  stream.match(/([a-zA-Z][A-Za-z0-9_]*)|(`.+`)/);\n  state.tokenize = tokenBase;\n  return \"def\";\n}\n\nfunction tokenFunProc(stream, state) {\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  if (!state.hasPassedFirstStage && stream.eat(\"{\")) {\n    state.hasPassedFirstStage = true;\n    return \"bracket\";\n  } else if (state.hasPassedFirstStage) {\n    stream.match(/([A-Z][A-Za-z0-9_]*)|(`.+`)|\\$/);\n    state.hasPassedFirstStage = false;\n    state.tokenize = tokenBase;\n    return \"def\";\n  } else {\n    state.tokenize = tokenBase;\n    return null;\n  }\n}\n\nfunction tokenComment(stream, state) {\n  var maybeEnd = false,\n      ch;\n\n  while (ch = stream.next()) {\n    if (ch == \"/\" && maybeEnd) {\n      state.tokenize = tokenBase;\n      break;\n    }\n\n    maybeEnd = ch == \"*\";\n  }\n\n  return \"comment\";\n}\n\nfunction tokenString(quote) {\n  return function (stream, state) {\n    var escaped = false,\n        next,\n        end = false;\n\n    while ((next = stream.next()) != null) {\n      if (next == quote && !escaped) {\n        end = true;\n        break;\n      }\n\n      escaped = !escaped && next == \"\\\\\";\n    }\n\n    if (end || !escaped) state.tokenize = tokenBase;\n    return \"string\";\n  };\n}\n\nfunction buildElectricInputRegEx() {\n  // Reindentation should occur on [] or on a match of any of\n  // the block closing keywords, at the end of a line.\n  var allClosings = middle.concat(end);\n  return new RegExp(\"[\\\\[\\\\]]|(\" + allClosings.join(\"|\") + \")$\");\n}\n\nexport var oz = {\n  startState: function startState() {\n    return {\n      tokenize: tokenBase,\n      currentIndent: 0,\n      doInCurrentLine: false,\n      hasPassedFirstStage: false\n    };\n  },\n  token: function token(stream, state) {\n    if (stream.sol()) state.doInCurrentLine = 0;\n    return state.tokenize(stream, state);\n  },\n  indent: function indent(state, textAfter, cx) {\n    var trueText = textAfter.replace(/^\\s+|\\s+$/g, '');\n    if (trueText.match(endKeywords) || trueText.match(middleKeywords) || trueText.match(/(\\[])/)) return cx.unit * (state.currentIndent - 1);\n    if (state.currentIndent < 0) return 0;\n    return state.currentIndent * cx.unit;\n  },\n  languageData: {\n    indentOnInut: buildElectricInputRegEx(),\n    commentTokens: {\n      line: \"%\",\n      block: {\n        open: \"/*\",\n        close: \"*/\"\n      }\n    }\n  }\n};"],"sourceRoot":""}