{"version":3,"sources":["../node_modules/@codemirror/legacy-modes/mode/coffeescript.js"],"names":["wordRegexp","words","RegExp","join","operators","delimiters","identifiers","atProp","wordOperators","indentKeywords","keywords","concat","stringPrefixes","regexPrefixes","constants","tokenBase","stream","state","sol","scope","align","scopeOffset","offset","eatSpace","lineOffset","indentation","type","dedent","ch","peek","match","skipToEnd","tokenize","longComment","floatLiteral","backUp","intLiteral","tokenFactory","current","prop","next","delimiter","singleline","outclass","eol","eatWhile","eat","indent","arguments","length","undefined","alignOffset","prev","indentUnit","column","_indent","matched","coffeeScript","startState","token","fillAlign","style","delimiter_index","indexOf","slice","exec","tokenLexer","text","closer","charAt","closes","languageData","commentTokens","line"],"mappings":"oGAAA,oDAEA,SAASA,EAAWC,GAClB,OAAO,IAAIC,OAAO,MAAQD,EAAME,KAAK,OAAS,SAGhD,IAAIC,EAAY,mHACZC,EAAa,gCACbC,EAAc,4BACdC,EAAS,6BACTC,EAAgBR,EAAW,CAAC,MAAO,KAAM,MAAO,KAAM,OAAQ,KAAM,aAAc,WAClFS,EAAiB,CAAC,MAAO,QAAS,OAAQ,KAAM,SAAU,OAAQ,SAAU,MAAO,QAAS,UAAW,SAEvGC,EAAWV,EAAWS,EAAeE,OADpB,CAAC,QAAS,KAAM,WAAY,WAAY,SAAU,KAAM,KAAM,KAAM,MAAO,SAAU,OAAQ,OAAQ,IAAK,QAAS,OAAQ,QAAS,aAEzJF,EAAiBT,EAAWS,GAC5B,IAAIG,EAAiB,sBACjBC,EAAgB,cAEhBC,EAAYd,EADM,CAAC,WAAY,MAAO,YAAa,OAAQ,OAAQ,QAAS,KAAM,MAAO,MAAO,OAGpG,SAASe,EAAUC,EAAQC,GAEzB,GAAID,EAAOE,MAAO,CACU,OAAtBD,EAAME,MAAMC,QAAgBH,EAAME,MAAMC,OAAQ,GACpD,IAAIC,EAAcJ,EAAME,MAAMG,OAE9B,GAAIN,EAAOO,WAAY,CACrB,IAAIC,EAAaR,EAAOS,cAExB,OAAID,EAAaH,GAAmC,UAApBJ,EAAME,MAAMO,KACnC,SACEF,EAAaH,EACf,SAGF,KAEHA,EAAc,GAChBM,EAAOX,EAAQC,GAKrB,GAAID,EAAOO,WACT,OAAO,KAGT,IAAIK,EAAKZ,EAAOa,OAEhB,GAAIb,EAAOc,MAAM,QAEf,OADAd,EAAOe,YACA,UAIT,GAAIf,EAAOc,MAAM,OAEf,OADAb,EAAMe,SAAWC,EACVhB,EAAMe,SAAShB,EAAQC,GAIhC,GAAW,MAAPW,EAEF,OADAZ,EAAOe,YACA,UAIT,GAAIf,EAAOc,MAAM,cAAc,GAAQ,CACrC,IAAII,GAAe,EAcnB,GAZIlB,EAAOc,MAAM,gCACfI,GAAe,GAGblB,EAAOc,MAAM,iBACfI,GAAe,GAGblB,EAAOc,MAAM,cACfI,GAAe,GAGbA,EAMF,MAJqB,KAAjBlB,EAAOa,QACTb,EAAOmB,OAAO,GAGT,SAIT,IAAIC,GAAa,EAgBjB,GAdIpB,EAAOc,MAAM,qBACfM,GAAa,GAIXpB,EAAOc,MAAM,+BACfM,GAAa,GAIXpB,EAAOc,MAAM,oBACfM,GAAa,GAGXA,EACF,MAAO,SAKX,GAAIpB,EAAOc,MAAMlB,GAEf,OADAK,EAAMe,SAAWK,EAAarB,EAAOsB,WAAW,EAAO,UAChDrB,EAAMe,SAAShB,EAAQC,GAIhC,GAAID,EAAOc,MAAMjB,GAAgB,CAC/B,GAAwB,KAApBG,EAAOsB,WAAoBtB,EAAOc,MAAM,SAAS,GAGnD,OADAb,EAAMe,SAAWK,EAAarB,EAAOsB,WAAW,EAAM,kBAC/CrB,EAAMe,SAAShB,EAAQC,GAE9BD,EAAOmB,OAAO,GAKlB,OAAInB,EAAOc,MAAM1B,IAAcY,EAAOc,MAAMtB,GACnC,WAGLQ,EAAOc,MAAMzB,GACR,cAGLW,EAAOc,MAAMhB,GACR,OAGLE,EAAOc,MAAMvB,IAAWU,EAAMsB,MAAQvB,EAAOc,MAAMxB,GAC9C,WAGLU,EAAOc,MAAMpB,GACR,UAGLM,EAAOc,MAAMxB,GACR,YAITU,EAAOwB,OA5JQ,SAgKjB,SAASH,EAAaI,EAAWC,EAAYC,GAC3C,OAAO,SAAU3B,EAAQC,GACvB,MAAQD,EAAO4B,OAGb,GAFA5B,EAAO6B,SAAS,aAEZ7B,EAAO8B,IAAI,OAGb,GAFA9B,EAAOwB,OAEHE,GAAc1B,EAAO4B,MACvB,OAAOD,MAEJ,IAAI3B,EAAOc,MAAMW,GAEtB,OADAxB,EAAMe,SAAWjB,EACV4B,EAEP3B,EAAO8B,IAAI,UAQf,OAJIJ,IACFzB,EAAMe,SAAWjB,GAGZ4B,GAIX,SAASV,EAAYjB,EAAQC,GAC3B,MAAQD,EAAO4B,OAAO,CAGpB,GAFA5B,EAAO6B,SAAS,QAEZ7B,EAAOc,MAAM,OAAQ,CACvBb,EAAMe,SAAWjB,EACjB,MAGFC,EAAO6B,SAAS,KAGlB,MAAO,UAGT,SAASE,EAAO/B,EAAQC,GAMtB,IALA,IAAIS,EAAOsB,UAAUC,OAAS,QAAsBC,IAAjBF,UAAU,GAAmBA,UAAU,GAAK,SAC3E1B,EAAS,EACTF,GAAQ,EACR+B,EAAc,KAEThC,EAAQF,EAAME,MAAOA,EAAOA,EAAQA,EAAMiC,KACjD,GAAmB,WAAfjC,EAAMO,MAAmC,KAAdP,EAAMO,KAAa,CAChDJ,EAASH,EAAMG,OAASN,EAAOqC,WAC/B,MAIS,WAAT3B,GACFN,EAAQ,KACR+B,EAAcnC,EAAOsC,SAAWtC,EAAOsB,UAAUW,QACxChC,EAAME,MAAMC,QACrBH,EAAME,MAAMC,OAAQ,GAGtBH,EAAME,MAAQ,CACZG,OAAQA,EACRI,KAAMA,EACN0B,KAAMnC,EAAME,MACZC,MAAOA,EACP+B,YAAaA,GAIjB,SAASxB,EAAOX,EAAQC,GACtB,GAAKA,EAAME,MAAMiC,KAAjB,CAEA,GAAyB,WAArBnC,EAAME,MAAMO,KAAmB,CAKjC,IAJA,IAAI6B,EAAUvC,EAAOS,cAEjB+B,GAAU,EAELrC,EAAQF,EAAME,MAAOA,EAAOA,EAAQA,EAAMiC,KACjD,GAAIG,IAAYpC,EAAMG,OAAQ,CAC5BkC,GAAU,EACV,MAIJ,IAAKA,EACH,OAAO,EAGT,KAAOvC,EAAME,MAAMiC,MAAQnC,EAAME,MAAMG,SAAWiC,GAChDtC,EAAME,MAAQF,EAAME,MAAMiC,KAG5B,OAAO,EAGP,OADAnC,EAAME,MAAQF,EAAME,MAAMiC,MACnB,GAsDJ,IAAIK,EAAe,CACxBC,WAAY,WACV,MAAO,CACL1B,SAAUjB,EACVI,MAAO,CACLG,OAAQ,EACRI,KAAM,SACN0B,KAAM,KACNhC,OAAO,GAETmB,MAAM,EACNZ,OAAQ,IAGZgC,MAAO,SAAe3C,EAAQC,GAC5B,IAAI2C,EAAkC,OAAtB3C,EAAME,MAAMC,OAAkBH,EAAME,MAChDyC,GAAa5C,EAAOE,QAAO0C,EAAUxC,OAAQ,GACjD,IAAIyC,EAnER,SAAoB7C,EAAQC,GAC1B,IAAI4C,EAAQ5C,EAAMe,SAAShB,EAAQC,GAC/BqB,EAAUtB,EAAOsB,UAEL,WAAZA,IACFrB,EAAMU,QAAS,KAGA,OAAZW,GAAgC,OAAZA,IAAqBtB,EAAO4B,OAAmB,WAAViB,IAC5Dd,EAAO/B,EAAQC,GAGjB,IAAI6C,EAAkB,MAAMC,QAAQzB,GAcpC,IAZyB,IAArBwB,GACFf,EAAO/B,EAAQC,EAAO,MAAM+C,MAAMF,EAAiBA,EAAkB,IAGnErD,EAAewD,KAAK3B,IACtBS,EAAO/B,EAAQC,GAGF,QAAXqB,GACFX,EAAOX,EAAQC,GAGH,WAAV4C,GACElC,EAAOX,EAAQC,GACjB,MAjSW,QAuSf,IAAyB,KAFzB6C,EAAkB,MAAMC,QAAQzB,IAEJ,CAC1B,KAA2B,UAApBrB,EAAME,MAAMO,MAAoBT,EAAME,MAAMiC,MACjDnC,EAAME,MAAQF,EAAME,MAAMiC,KAGxBnC,EAAME,MAAMO,MAAQY,IAASrB,EAAME,MAAQF,EAAME,MAAMiC,MAQ7D,OALInC,EAAMU,QAAUX,EAAO4B,QACD,UAApB3B,EAAME,MAAMO,MAAoBT,EAAME,MAAMiC,OAAMnC,EAAME,MAAQF,EAAME,MAAMiC,MAChFnC,EAAMU,QAAS,GAGD,UAATkC,GAA8B,UAATA,EAAoB,KAAOA,EAoBzCK,CAAWlD,EAAQC,GAO/B,OALI4C,GAAkB,WAATA,IACPD,IAAWA,EAAUxC,OAAQ,GACjCH,EAAMsB,KAAgB,eAATsB,GAA8C,KAApB7C,EAAOsB,WAGzCuB,GAETd,OAAQ,SAAgB9B,EAAOkD,GAC7B,GAAIlD,EAAMe,UAAYjB,EAAW,OAAO,EACxC,IAAII,EAAQF,EAAME,MACdiD,EAASD,GAAQ,MAAMJ,QAAQI,EAAKE,OAAO,KAAO,EACtD,GAAID,EAAQ,KAAqB,UAAdjD,EAAMO,MAAoBP,EAAMiC,MACjDjC,EAAQA,EAAMiC,KAEhB,IAAIkB,EAASF,GAAUjD,EAAMO,OAASyC,EAAKE,OAAO,GAClD,OAAIlD,EAAMC,MAAcD,EAAMgC,aAAemB,EAAS,EAAI,IAAgBA,EAASnD,EAAMiC,KAAOjC,GAAOG,QAEzGiD,aAAc,CACZC,cAAe,CACbC,KAAM","file":"static/js/31.92952a8c.chunk.js","sourcesContent":["var ERRORCLASS = \"error\";\n\nfunction wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\n\nvar operators = /^(?:->|=>|\\+[+=]?|-[\\-=]?|\\*[\\*=]?|\\/[\\/=]?|[=!]=|<[><]?=?|>>?=?|%=?|&=?|\\|=?|\\^=?|\\~|!|\\?|(or|and|\\|\\||&&|\\?)=)/;\nvar delimiters = /^(?:[()\\[\\]{},:`=;]|\\.\\.?\\.?)/;\nvar identifiers = /^[_A-Za-z$][_A-Za-z$0-9]*/;\nvar atProp = /^@[_A-Za-z$][_A-Za-z$0-9]*/;\nvar wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\", \"isnt\", \"in\", \"instanceof\", \"typeof\"]);\nvar indentKeywords = [\"for\", \"while\", \"loop\", \"if\", \"unless\", \"else\", \"switch\", \"try\", \"catch\", \"finally\", \"class\"];\nvar commonKeywords = [\"break\", \"by\", \"continue\", \"debugger\", \"delete\", \"do\", \"in\", \"of\", \"new\", \"return\", \"then\", \"this\", \"@\", \"throw\", \"when\", \"until\", \"extends\"];\nvar keywords = wordRegexp(indentKeywords.concat(commonKeywords));\nindentKeywords = wordRegexp(indentKeywords);\nvar stringPrefixes = /^('{3}|\\\"{3}|['\\\"])/;\nvar regexPrefixes = /^(\\/{3}|\\/)/;\nvar commonConstants = [\"Infinity\", \"NaN\", \"undefined\", \"null\", \"true\", \"false\", \"on\", \"off\", \"yes\", \"no\"];\nvar constants = wordRegexp(commonConstants); // Tokenizers\n\nfunction tokenBase(stream, state) {\n  // Handle scope changes\n  if (stream.sol()) {\n    if (state.scope.align === null) state.scope.align = false;\n    var scopeOffset = state.scope.offset;\n\n    if (stream.eatSpace()) {\n      var lineOffset = stream.indentation();\n\n      if (lineOffset > scopeOffset && state.scope.type == \"coffee\") {\n        return \"indent\";\n      } else if (lineOffset < scopeOffset) {\n        return \"dedent\";\n      }\n\n      return null;\n    } else {\n      if (scopeOffset > 0) {\n        dedent(stream, state);\n      }\n    }\n  }\n\n  if (stream.eatSpace()) {\n    return null;\n  }\n\n  var ch = stream.peek(); // Handle docco title comment (single line)\n\n  if (stream.match(\"####\")) {\n    stream.skipToEnd();\n    return \"comment\";\n  } // Handle multi line comments\n\n\n  if (stream.match(\"###\")) {\n    state.tokenize = longComment;\n    return state.tokenize(stream, state);\n  } // Single line comment\n\n\n  if (ch === \"#\") {\n    stream.skipToEnd();\n    return \"comment\";\n  } // Handle number literals\n\n\n  if (stream.match(/^-?[0-9\\.]/, false)) {\n    var floatLiteral = false; // Floats\n\n    if (stream.match(/^-?\\d*\\.\\d+(e[\\+\\-]?\\d+)?/i)) {\n      floatLiteral = true;\n    }\n\n    if (stream.match(/^-?\\d+\\.\\d*/)) {\n      floatLiteral = true;\n    }\n\n    if (stream.match(/^-?\\.\\d+/)) {\n      floatLiteral = true;\n    }\n\n    if (floatLiteral) {\n      // prevent from getting extra . on 1..\n      if (stream.peek() == \".\") {\n        stream.backUp(1);\n      }\n\n      return \"number\";\n    } // Integers\n\n\n    var intLiteral = false; // Hex\n\n    if (stream.match(/^-?0x[0-9a-f]+/i)) {\n      intLiteral = true;\n    } // Decimal\n\n\n    if (stream.match(/^-?[1-9]\\d*(e[\\+\\-]?\\d+)?/)) {\n      intLiteral = true;\n    } // Zero by itself with no other piece of number.\n\n\n    if (stream.match(/^-?0(?![\\dx])/i)) {\n      intLiteral = true;\n    }\n\n    if (intLiteral) {\n      return \"number\";\n    }\n  } // Handle strings\n\n\n  if (stream.match(stringPrefixes)) {\n    state.tokenize = tokenFactory(stream.current(), false, \"string\");\n    return state.tokenize(stream, state);\n  } // Handle regex literals\n\n\n  if (stream.match(regexPrefixes)) {\n    if (stream.current() != \"/\" || stream.match(/^.*\\//, false)) {\n      // prevent highlight of division\n      state.tokenize = tokenFactory(stream.current(), true, \"string.special\");\n      return state.tokenize(stream, state);\n    } else {\n      stream.backUp(1);\n    }\n  } // Handle operators and delimiters\n\n\n  if (stream.match(operators) || stream.match(wordOperators)) {\n    return \"operator\";\n  }\n\n  if (stream.match(delimiters)) {\n    return \"punctuation\";\n  }\n\n  if (stream.match(constants)) {\n    return \"atom\";\n  }\n\n  if (stream.match(atProp) || state.prop && stream.match(identifiers)) {\n    return \"property\";\n  }\n\n  if (stream.match(keywords)) {\n    return \"keyword\";\n  }\n\n  if (stream.match(identifiers)) {\n    return \"variable\";\n  } // Handle non-detected items\n\n\n  stream.next();\n  return ERRORCLASS;\n}\n\nfunction tokenFactory(delimiter, singleline, outclass) {\n  return function (stream, state) {\n    while (!stream.eol()) {\n      stream.eatWhile(/[^'\"\\/\\\\]/);\n\n      if (stream.eat(\"\\\\\")) {\n        stream.next();\n\n        if (singleline && stream.eol()) {\n          return outclass;\n        }\n      } else if (stream.match(delimiter)) {\n        state.tokenize = tokenBase;\n        return outclass;\n      } else {\n        stream.eat(/['\"\\/]/);\n      }\n    }\n\n    if (singleline) {\n      state.tokenize = tokenBase;\n    }\n\n    return outclass;\n  };\n}\n\nfunction longComment(stream, state) {\n  while (!stream.eol()) {\n    stream.eatWhile(/[^#]/);\n\n    if (stream.match(\"###\")) {\n      state.tokenize = tokenBase;\n      break;\n    }\n\n    stream.eatWhile(\"#\");\n  }\n\n  return \"comment\";\n}\n\nfunction indent(stream, state) {\n  var type = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : \"coffee\";\n  var offset = 0,\n      align = false,\n      alignOffset = null;\n\n  for (var scope = state.scope; scope; scope = scope.prev) {\n    if (scope.type === \"coffee\" || scope.type == \"}\") {\n      offset = scope.offset + stream.indentUnit;\n      break;\n    }\n  }\n\n  if (type !== \"coffee\") {\n    align = null;\n    alignOffset = stream.column() + stream.current().length;\n  } else if (state.scope.align) {\n    state.scope.align = false;\n  }\n\n  state.scope = {\n    offset: offset,\n    type: type,\n    prev: state.scope,\n    align: align,\n    alignOffset: alignOffset\n  };\n}\n\nfunction dedent(stream, state) {\n  if (!state.scope.prev) return;\n\n  if (state.scope.type === \"coffee\") {\n    var _indent = stream.indentation();\n\n    var matched = false;\n\n    for (var scope = state.scope; scope; scope = scope.prev) {\n      if (_indent === scope.offset) {\n        matched = true;\n        break;\n      }\n    }\n\n    if (!matched) {\n      return true;\n    }\n\n    while (state.scope.prev && state.scope.offset !== _indent) {\n      state.scope = state.scope.prev;\n    }\n\n    return false;\n  } else {\n    state.scope = state.scope.prev;\n    return false;\n  }\n}\n\nfunction tokenLexer(stream, state) {\n  var style = state.tokenize(stream, state);\n  var current = stream.current(); // Handle scope changes.\n\n  if (current === \"return\") {\n    state.dedent = true;\n  }\n\n  if ((current === \"->\" || current === \"=>\") && stream.eol() || style === \"indent\") {\n    indent(stream, state);\n  }\n\n  var delimiter_index = \"[({\".indexOf(current);\n\n  if (delimiter_index !== -1) {\n    indent(stream, state, \"])}\".slice(delimiter_index, delimiter_index + 1));\n  }\n\n  if (indentKeywords.exec(current)) {\n    indent(stream, state);\n  }\n\n  if (current == \"then\") {\n    dedent(stream, state);\n  }\n\n  if (style === \"dedent\") {\n    if (dedent(stream, state)) {\n      return ERRORCLASS;\n    }\n  }\n\n  delimiter_index = \"])}\".indexOf(current);\n\n  if (delimiter_index !== -1) {\n    while (state.scope.type == \"coffee\" && state.scope.prev) {\n      state.scope = state.scope.prev;\n    }\n\n    if (state.scope.type == current) state.scope = state.scope.prev;\n  }\n\n  if (state.dedent && stream.eol()) {\n    if (state.scope.type == \"coffee\" && state.scope.prev) state.scope = state.scope.prev;\n    state.dedent = false;\n  }\n\n  return style == \"indent\" || style == \"dedent\" ? null : style;\n}\n\nexport var coffeeScript = {\n  startState: function startState() {\n    return {\n      tokenize: tokenBase,\n      scope: {\n        offset: 0,\n        type: \"coffee\",\n        prev: null,\n        align: false\n      },\n      prop: false,\n      dedent: 0\n    };\n  },\n  token: function token(stream, state) {\n    var fillAlign = state.scope.align === null && state.scope;\n    if (fillAlign && stream.sol()) fillAlign.align = false;\n    var style = tokenLexer(stream, state);\n\n    if (style && style != \"comment\") {\n      if (fillAlign) fillAlign.align = true;\n      state.prop = style == \"punctuation\" && stream.current() == \".\";\n    }\n\n    return style;\n  },\n  indent: function indent(state, text) {\n    if (state.tokenize != tokenBase) return 0;\n    var scope = state.scope;\n    var closer = text && \"])}\".indexOf(text.charAt(0)) > -1;\n    if (closer) while (scope.type == \"coffee\" && scope.prev) {\n      scope = scope.prev;\n    }\n    var closes = closer && scope.type === text.charAt(0);\n    if (scope.align) return scope.alignOffset - (closes ? 1 : 0);else return (closes ? scope.prev : scope).offset;\n  },\n  languageData: {\n    commentTokens: {\n      line: \"#\"\n    }\n  }\n};"],"sourceRoot":""}